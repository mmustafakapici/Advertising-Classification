{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Import Libraries"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": " dataset link : https://www.kaggle.com/datasets/gabrielsantello/advertisement-click-on-ad"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "ads = pd.read_csv('advertising.csv')\n",
    "df = ads.copy()\n",
    "df.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Exploratory Data Analysis"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.info()",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df['Timestamp'] = pd.to_datetime(df['Timestamp'])",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.describe().T",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.isnull().sum()",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df['Clicked on Ad'].value_counts()",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "sns.countplot(x='Clicked on Ad', data=df)",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "sns.pairplot(data = df.drop(\"Male\",axis=1), hue='Clicked on Ad')",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "sns.scatterplot(x='Daily Time Spent on Site', y='Age', hue='Clicked on Ad', data=df)",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "numerical_cols= ['Daily Time Spent on Site','Daily Internet Usage','Area Income','Age']\n",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def boxPlot(df):\n",
    "    for i,col in enumerate(numerical_cols,start=1):\n",
    "        plt.subplot(2,2,i)\n",
    "        sns.boxplot(x = 'Clicked on Ad', y = col, data = df, palette = 'coolwarm_r')\n",
    "    plt.subplots_adjust(left = 0.1,right=0.9,wspace=0.4,hspace=0.4)\n",
    " \n",
    " \n",
    "def distPlot(df):\n",
    "    for i,col in enumerate(numerical_cols,start=1):\n",
    "        plt.subplot(2,2,i)\n",
    "        sns.distplot(df[col],bins=20)   \n",
    "    plt.subplots_adjust(left = 0.1,right=0.9,wspace=0.4,hspace=0.4)\n",
    "    \n",
    "def linePlot(df):\n",
    "    df['Months'] = df['Timestamp'].apply(lambda x: x.month)\n",
    "    df['Days'] = df['Timestamp'].apply(lambda x: x.day)\n",
    "    df['Hours'] = df['Timestamp'].apply(lambda x: x.hour)\n",
    "\n",
    "    date_columns = ['Months','Hours','Days']\n",
    "\n",
    "    for i,col in enumerate(date_columns,start=1):\n",
    "        plt.subplot(2,2,i)\n",
    "        sns.lineplot(df.groupby(col)['Clicked on Ad'].sum())\n",
    "        plt.xlabel(col,size = 14)\n",
    "        plt.ylabel('Clicked on Ad',size = 14)\n",
    "        plt.xticks(size = 12)\n",
    "        plt.yticks(size = 12)\n",
    "\n",
    "    plt.suptitle('Sum of Clicked on Ad',size = 16)\n",
    "    plt.subplots_adjust(left = 0.1,right=0.9,wspace=0.4,hspace=0.4)\n",
    "    \n",
    "def cal(df):\n",
    "    print('Clicked on Ad Rates'.center(50,'_'))\n",
    "\n",
    "    for col in numerical_cols:\n",
    "        print('\\n')\n",
    "        print(f'{col} <= mean - std: {round(df[df[col] <= df[col].mean() - df[col].std()][\"Clicked on Ad\"].mean()*100,2)}%')\n",
    "        print(f'{col} <= mean: {round(df[df[col] <= df[col].mean()][\"Clicked on Ad\"].mean()*100,2)}%')\n",
    "        print(f'{col} >= mean: {round(df[df[col] >= df[col].mean()][\"Clicked on Ad\"].mean()*100,2)}%')\n",
    "        print(f'{col} >= mean + std: {round(df[df[col] >= df[col].mean() + df[col].std()][\"Clicked on Ad\"].mean()*100,2)}%')\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "boxPlot(df)",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "cal(df)",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "distPlot(df)",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "linePlot(df)",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "#sns.heatmap(df.corr(), annot=True, cmap='coolwarm')",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import openpyxl\n",
    "pv_timestamp = df.pivot_table(values='Clicked on Ad', index=['Days','Hours'],columns='Months', aggfunc='sum').fillna(0)\n",
    "pv_timestamp.to_excel('timestamp.xlsx')\n",
    "pv_timestamp"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Data Preprocessing"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### - Create Independent and Dependent Variables"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X = df.drop(['Clicked on Ad','Ad Topic Line','City','Country','Timestamp', 'Months','Days', 'Hours'], axis=1) # Drop Features\n",
    "y = df['Clicked on Ad'].values # Target Variable"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "X.head()",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import cross_val_score,GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,precision_score,recall_score , f1_score\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "#from lightgbm import LGBMClassifier\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model Building"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def random_forest():\n",
    "    classifier = RandomForestClassifier(criterion='entropy',n_estimators = 100,random_state=0).fit(X_train,y_train)\n",
    "    return classifier"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def decision_tree():\n",
    "    classifier = DecisionTreeClassifier(\n",
    "        criterion='gini',\n",
    "        max_depth = 4,\n",
    "        min_samples_split = 4,\n",
    "        random_state=0\n",
    "    ).fit(X_train,y_train)\n",
    "    return classifier"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def knn():\n",
    "    classifier = KNeighborsClassifier(n_neighbors=9).fit(X_train,y_train)\n",
    "    return classifier"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def naive_bayes():\n",
    "    classifier = GaussianNB().fit(X_train,y_train)\n",
    "    return classifier"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def mlp():\n",
    "    classifier = MLPClassifier(\n",
    "        early_stopping=True,\n",
    "        batch_size=32,\n",
    "        random_state=0\n",
    "    ).fit(X_train,y_train)\n",
    "\n",
    "    return classifier"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def logistic_reg():\n",
    "    classifier = LogisticRegression(random_state=0,C=1).fit(X_train,y_train)\n",
    "    return classifier"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def xgboost():\n",
    "    classifier = XGBClassifier(learning_rate =  0.1,\n",
    "                               max_depth = 4,\n",
    "                               n_estimators = 100,\n",
    "                               subsample = 0.8\n",
    "                               ).fit(X_train,y_train)\n",
    "    return classifier"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "classifiers = {'Random Forest':random_forest(),'Decision Tree':decision_tree(),'KNN':knn(),\n",
    "               'Naive Bayes':naive_bayes(),'MLP':mlp(),'Logistic Regression':logistic_reg(),\n",
    "               'XGBoost':xgboost()}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "parameters = {\n",
    "    'Random Forest': {\"max_depth\": [None,5,8,10],\"n_estimators\": [100,500,1000], 'criterion':['entropy','gini']},\n",
    "    'Decision Tree': {'criterion': ['entropy','gini'], \"max_depth\": range(1,10), \"min_samples_split\" : list(range(2,50))},\n",
    "    'KNN': {'n_neighbors': np.arange(1,20,step = 2)},\n",
    "    'Logistic Regression': {'C':[1.0,2.0,3.0,4.0,5.0]},\n",
    "    'XGBoost': {'n_estimators': [100, 500, 1000],'subsample': [0.6, 0.8, 1.0],'max_depth': [4, 5, 6],'learning_rate': [0.1, 0.01, 0.02]},\n",
    "    'MLP': {'batch_size': [16,32,64],'early_stopping': [True,False]},\n",
    "    'Naive Bayes': {}\n",
    "    \n",
    "    \n",
    "    }"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def grid_search(classifiers,parameters):\n",
    "    best_params = {}\n",
    "    for key in classifiers.keys():\n",
    "        \n",
    "        ## Add parameters to grid search\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator = classifiers[key],\n",
    "            param_grid = parameters[key],\n",
    "            scoring = 'accuracy',\n",
    "            cv = 10,\n",
    "            n_jobs = -1,\n",
    "            verbose = 1,\n",
    "            return_train_score = True)\n",
    "        \n",
    "        ## Fit the model\n",
    "        grid_search.fit(X_train,y_train)\n",
    "        \n",
    "        ## Get the best parameters and accuracy\n",
    "        best_params[key] = grid_search.best_params_\n",
    "        print(f\"{key} best parameters: {grid_search.best_params_}\")\n",
    "        print(f\"{key} best accuracy: {grid_search.best_score_}\")\n",
    "        \n",
    "    return best_params\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"This process may take a while, please wait...\")\n",
    "\n",
    "\n",
    "for key in classifiers.keys():\n",
    "    print(f\"Grid Search for {key} is started\")\n",
    "    grid_search(classifiers,parameters)\n",
    "    print(f\"Grid Search for {key} is completed\")\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model Evaluation"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate(classifiers):\n",
    "    results = pd.DataFrame(columns = ['Model','Accuracy','Precision',\n",
    "                                      'Recall', 'F1 Score' , 'CVS (Mean)' , 'CVS (STD)%',\n",
    "                                      'TP','TN','FP','FN'])\n",
    "    for key in classifiers.keys():\n",
    "        y_pred = classifiers[key].predict(X_test)\n",
    "        results = results.append({\n",
    "            'Model': key,\n",
    "            'Accuracy': accuracy_score(y_test,y_pred),\n",
    "            'Precision': precision_score(y_test,y_pred),\n",
    "            'Recall': recall_score(y_test,y_pred),\n",
    "            'F1 Score': f1_score(y_test,y_pred),\n",
    "            'CVS (Mean)': cross_val_score(classifiers[key],X_train,y_train,cv=10).mean(),\n",
    "            'CVS (STD)%': cross_val_score(classifiers[key],X_train,y_train,cv=10).std()*100,\n",
    "            'TP': confusion_matrix(y_test,y_pred)[0][0],\n",
    "            'TN': confusion_matrix(y_test,y_pred)[1][1],\n",
    "            'FP': confusion_matrix(y_test,y_pred)[0][1],\n",
    "            'FN': confusion_matrix(y_test,y_pred)[1][0]\n",
    "            \n",
    "        },ignore_index=True)\n",
    "    return results\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "results = evaluate(classifiers)\n",
    "results\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model Comparison"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "## classification report\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "for key in classifiers.keys():\n",
    "    print(f\"{key} classification report: \\n{classification_report(y_test,classifiers[key].predict(X_test))}\")\n",
    "    "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Prediction"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "# df.describe().transpose()",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# predictions = [[enter_values_of_each_column]]\n",
    "# predictions = sc.transform(predictions)\n",
    "\n",
    "# print(classifiers['enter_algorithm_name'].predict(predictions)[0])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Save Model"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# import pickle\n",
    "# try:\n",
    "#     with open('your_file_name', 'wb') as file:  \n",
    "#         pickle.dump(classifiers['enter_algorithm_name'], file)\n",
    "#     print('Model Saved')\n",
    "# except:\n",
    "#     print('Invalid Algorithm Name!')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Load Model"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# try:\n",
    "#     with open('your_file_name', 'rb') as file:  \n",
    "#         my_model = pickle.load(file)\n",
    "#     print('Model Loaded')\n",
    "# except:\n",
    "#     print('Invalid Filename!')"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "all",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
